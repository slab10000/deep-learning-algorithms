{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfeff85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Setup Device (MPS for Mac, CUDA for Nvidia, else CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6041a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            img_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # We need to map sides (3,4,5,6) to model indices (0,1,2,3)\n",
    "        self.class_map = {3: 0, 4: 1, 5: 2, 6: 3}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Get image name from the 'filename' column\n",
    "        img_name = os.path.join(self.img_dir, self.data_frame.iloc[idx]['filename'])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        # Get label from the 'sides' column\n",
    "        sides = self.data_frame.iloc[idx]['sides']\n",
    "        label = self.class_map[sides] # Convert 3->0, 4->1, etc.\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dd9efe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: 8000 training images, 2000 test images.\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMETERS\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "# Define Paths (CHANGE THESE TO YOUR ACTUAL PATHS)\n",
    "CSV_PATH = '/Users/blasmorenolaguna/Documents/TODO/University/Applied ML/CNN/archive/targets.csv'      # Path to your uploaded csv\n",
    "IMG_FOLDER = '/Users/blasmorenolaguna/Documents/TODO/University/Applied ML/CNN/archive/images/content/images' # Path to the folder containing the images\n",
    "\n",
    "# 1. Define Transforms\n",
    "# We resize to 64x64. You can increase this to 128x128 if shapes are complex, \n",
    "# but 64 is usually fine for geometric shapes.\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# 2. Instantiate Dataset\n",
    "full_dataset = ShapesDataset(csv_file=CSV_PATH, img_dir=IMG_FOLDER, transform=data_transform)\n",
    "\n",
    "# 3. Split into Train and Test (e.g., 80% Train, 20% Test)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "# 4. Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Data loaded: {len(train_dataset)} training images, {len(test_dataset)} test images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c209468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShapeClassifier, self).__init__()\n",
    "        \n",
    "        # Convolutional layers to extract features\n",
    "        self.features = nn.Sequential(\n",
    "            # Conv Layer 1: Input 3 channels (RGB), Output 16 channels\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # Image becomes 32x32\n",
    "            \n",
    "            # Conv Layer 2\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # Image becomes 16x16\n",
    "            \n",
    "            # Conv Layer 3\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # Image becomes 8x8\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers for classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 128), # 64 channels * 8x8 image size\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 4) # Output is 4 (Triangle, Square, Pentagon, Hexagon)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = ShapeClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80d80522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.3147\n",
      "Epoch [2/20], Loss: 0.2890\n",
      "Epoch [3/20], Loss: 0.2739\n",
      "Epoch [4/20], Loss: 0.2548\n",
      "Epoch [5/20], Loss: 0.2273\n",
      "Epoch [6/20], Loss: 0.2113\n",
      "Epoch [7/20], Loss: 0.2019\n",
      "Epoch [8/20], Loss: 0.1794\n",
      "Epoch [9/20], Loss: 0.1850\n",
      "Epoch [10/20], Loss: 0.1607\n",
      "Epoch [11/20], Loss: 0.1564\n",
      "Epoch [12/20], Loss: 0.1573\n",
      "Epoch [13/20], Loss: 0.1334\n",
      "Epoch [14/20], Loss: 0.1215\n",
      "Epoch [15/20], Loss: 0.1107\n",
      "Epoch [16/20], Loss: 0.1069\n",
      "Epoch [17/20], Loss: 0.0950\n",
      "Epoch [18/20], Loss: 0.1014\n",
      "Epoch [19/20], Loss: 0.0889\n",
      "Epoch [20/20], Loss: 0.0879\n",
      "Training Finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train() # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b976ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[479   5   0   0]\n",
      " [  1 478   5   0]\n",
      " [  0   3 495  15]\n",
      " [  0   0  29 490]]\n",
      "--------------------\n",
      "Precision: 0.971\n",
      "Recall:    0.971\n",
      "F1 Score:  0.971\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(y_true, y_pred):\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred, average='weighted'):.3f}\")\n",
    "    print(f\"Recall:    {recall_score(y_true, y_pred, average='weighted'):.3f}\")\n",
    "    print(f\"F1 Score:  {f1_score(y_true, y_pred, average='weighted'):.3f}\")\n",
    "\n",
    "model.eval() # Set model to evaluation mode\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Map indices back to names for clarity if needed, but metrics function takes numbers\n",
    "print_metrics(all_labels, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73716886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image Classification Result (Random Test Image #1331):\n",
      "True Class: hexagon (class 3)\n",
      "Predicted Class: hexagon (class 3)\n",
      "✓ Correct prediction!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Class mapping\n",
    "class_names = {0: 'triangle', 1: 'square', 2: 'pentagon', 3: 'hexagon'}\n",
    "\n",
    "# Get a random sample image from test dataset\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Randomly pick an index from the test dataset\n",
    "    random_idx = random.randint(0, len(test_dataset) - 1)\n",
    "    \n",
    "    # Get the image and label at that random index\n",
    "    sample_image, true_label = test_dataset[random_idx]\n",
    "    \n",
    "    # Add batch dimension and move to device\n",
    "    sample_image = sample_image.unsqueeze(0).to(device)  # Shape: (1, C, H, W)\n",
    "    true_label = true_label\n",
    "    \n",
    "    # Get prediction\n",
    "    outputs = model(sample_image)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    predicted_class = predicted[0].item()\n",
    "    \n",
    "    # Get the image for display (denormalize and convert to numpy)\n",
    "    img_display = sample_image[0].cpu()  # Remove batch dimension\n",
    "    \n",
    "    # Denormalize: reverse the normalization (mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    img_display = img_display * 0.5 + 0.5  # Reverse: (x * std) + mean = (x * 0.5) + 0.5\n",
    "    img_display = torch.clamp(img_display, 0, 1)  # Ensure values are in [0, 1]\n",
    "    \n",
    "    # Convert to numpy and change from (C, H, W) to (H, W, C) for matplotlib\n",
    "    img_np = img_display.permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # Display the image\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img_np)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'True Label: {class_names[true_label]}\\nPredicted: {class_names[predicted_class]}', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification result\n",
    "    print(f\"\\nImage Classification Result (Random Test Image #{random_idx}):\")\n",
    "    print(f\"True Class: {class_names[true_label]} (class {true_label})\")\n",
    "    print(f\"Predicted Class: {class_names[predicted_class]} (class {predicted_class})\")\n",
    "    if true_label == predicted_class:\n",
    "        print(\"✓ Correct prediction!\")\n",
    "    else:\n",
    "        print(\"✗ Incorrect prediction\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
